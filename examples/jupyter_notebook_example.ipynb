{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ§  LitKG SDK - Interactive Knowledge Graph Construction\n",
    "\n",
    "This notebook demonstrates how to use LitKG SDK to convert PDF literature into interactive knowledge graphs with human-in-the-loop validation.\n",
    "\n",
    "## Features Demonstrated\n",
    "- ğŸ“„ PDF upload and processing\n",
    "- ğŸ¤– LLM-powered entity and relation extraction\n",
    "- âœ… Interactive human validation\n",
    "- ğŸ“Š Knowledge graph visualization\n",
    "- ğŸ˜ï¸ Community detection\n",
    "- â° Temporal analysis\n",
    "- ğŸ’¾ Multiple export formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Setup and Installation\n",
    "\n",
    "First, install LitKG SDK with all dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install LitKG SDK (run once)\n",
    "!pip install lit-kg-sdk[all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import litkg\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up API keys (you can also use environment variables)\n",
    "# os.environ['OPENAI_API_KEY'] = 'your_openai_key_here'\n",
    "# os.environ['ANTHROPIC_API_KEY'] = 'your_anthropic_key_here'\n",
    "\n",
    "print(\"âœ… LitKG SDK imported successfully!\")\n",
    "print(f\"ğŸ“¦ Version: {litkg.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Create Session with LLM\n",
    "\n",
    "Choose your preferred LLM provider and model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create session with GPT-4 (recommended)\n",
    "session = litkg.create_session(\n",
    "    llm=\"gpt-4\",                    # or \"claude-3.5-sonnet\", \"ollama/llama3.1\"\n",
    "    confidence_threshold=0.7,       # Minimum confidence for extractions\n",
    "    enable_communities=True,        # Enable community detection\n",
    "    enable_temporal=True,           # Enable temporal tracking\n",
    "    domain=\"general\"                # or \"biomedical\", \"computer_science\", etc.\n",
    ")\n",
    "\n",
    "print(\"ğŸ§  Session created with advanced LLM capabilities!\")\n",
    "print(f\"ğŸ“Š Configuration: {session.config.llm_provider} - {session.config.llm_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Upload and Process PDF\n",
    "\n",
    "Upload your research papers and automatically extract knowledge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single PDF processing\n",
    "# kg = session.upload_pdf(\n",
    "#     \"your_research_paper.pdf\",\n",
    "#     preserve_structure=True,      # Maintain document hierarchy\n",
    "#     chunking_strategy=\"semantic\"  # Intelligent text chunking\n",
    "# )\n",
    "\n",
    "# For demo purposes, let's create a sample knowledge graph\n",
    "kg = litkg.KnowledgeGraph(session)\n",
    "\n",
    "# Add sample entities\n",
    "from litkg.core.knowledge_graph import Entity, Relation\n",
    "\n",
    "# Sample research entities\n",
    "entities = [\n",
    "    Entity(\"llm_1\", \"Large Language Models\", \"Concept\", \n",
    "           {\"field\": \"AI\", \"year\": 2023}, 0.95, \"demo_paper.pdf\"),\n",
    "    Entity(\"gpt4_1\", \"GPT-4\", \"Model\", \n",
    "           {\"company\": \"OpenAI\", \"parameters\": \"1.76T\"}, 0.98, \"demo_paper.pdf\"),\n",
    "    Entity(\"kg_1\", \"Knowledge Graphs\", \"Concept\", \n",
    "           {\"field\": \"AI\", \"application\": \"information_extraction\"}, 0.92, \"demo_paper.pdf\"),\n",
    "    Entity(\"rag_1\", \"Retrieval Augmented Generation\", \"Method\", \n",
    "           {\"year\": 2020, \"improves\": \"factual_accuracy\"}, 0.89, \"demo_paper.pdf\"),\n",
    "    Entity(\"neo4j_1\", \"Neo4j\", \"Tool\", \n",
    "           {\"type\": \"graph_database\", \"query_language\": \"Cypher\"}, 0.94, \"demo_paper.pdf\")\n",
    "]\n",
    "\n",
    "for entity in entities:\n",
    "    kg.add_entity(entity)\n",
    "\n",
    "# Sample relations\n",
    "relations = [\n",
    "    Relation(\"rel_1\", \"gpt4_1\", \"llm_1\", \"InstanceOf\", \n",
    "             {\"specificity\": \"high\"}, 0.96, \"demo_paper.pdf\"),\n",
    "    Relation(\"rel_2\", \"llm_1\", \"kg_1\", \"UsedFor\", \n",
    "             {\"purpose\": \"knowledge_extraction\"}, 0.87, \"demo_paper.pdf\"),\n",
    "    Relation(\"rel_3\", \"rag_1\", \"llm_1\", \"EnhancementOf\", \n",
    "             {\"improvement\": \"factual_accuracy\"}, 0.91, \"demo_paper.pdf\"),\n",
    "    Relation(\"rel_4\", \"kg_1\", \"neo4j_1\", \"StoredIn\", \n",
    "             {\"format\": \"property_graph\"}, 0.93, \"demo_paper.pdf\")\n",
    "]\n",
    "\n",
    "for relation in relations:\n",
    "    kg.add_relation(relation)\n",
    "\n",
    "print(f\"ğŸ“„ Knowledge graph created!\")\n",
    "print(f\"   ğŸ“Š Entities: {len(kg.entities)}\")\n",
    "print(f\"   ğŸ”— Relations: {len(kg.relations)}\")\n",
    "print(f\"   ğŸ“ˆ Avg Confidence: {sum(e.confidence for e in kg.entities.values()) / len(kg.entities):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Interactive Human Validation\n",
    "\n",
    "Launch the interactive interface for human-in-the-loop validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch interactive validation interface\n",
    "kg.collaborate_interactively()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Knowledge Graph Analysis\n",
    "\n",
    "Analyze the constructed knowledge graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity type distribution\n",
    "entity_types = {}\n",
    "for entity in kg.entities.values():\n",
    "    entity_types[entity.type] = entity_types.get(entity.type, 0) + 1\n",
    "\n",
    "print(\"ğŸ“Š Entity Type Distribution:\")\n",
    "for etype, count in sorted(entity_types.items()):\n",
    "    print(f\"   {etype}: {count}\")\n",
    "\n",
    "# Relation type distribution\n",
    "relation_types = {}\n",
    "for relation in kg.relations.values():\n",
    "    relation_types[relation.type] = relation_types.get(relation.type, 0) + 1\n",
    "\n",
    "print(\"\\nğŸ”— Relation Type Distribution:\")\n",
    "for rtype, count in sorted(relation_types.items()):\n",
    "    print(f\"   {rtype}: {count}\")\n",
    "\n",
    "# Confidence statistics\n",
    "confidences = [e.confidence for e in kg.entities.values()] + [r.confidence for r in kg.relations.values()]\n",
    "print(f\"\\nğŸ“ˆ Confidence Statistics:\")\n",
    "print(f\"   Mean: {sum(confidences) / len(confidences):.3f}\")\n",
    "print(f\"   Min: {min(confidences):.3f}\")\n",
    "print(f\"   Max: {max(confidences):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ Community Detection\n",
    "\n",
    "Discover communities and clusters in your knowledge graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze communities\n",
    "communities = kg.analyze_communities()\n",
    "\n",
    "print(\"ğŸ˜ï¸ Community Analysis:\")\n",
    "print(f\"   Number of communities: {communities.get('num_communities', 0)}\")\n",
    "if 'modularity' in communities and communities['modularity']:\n",
    "    print(f\"   Modularity score: {communities['modularity']:.3f}\")\n",
    "\n",
    "# Show community membership\n",
    "if 'communities' in communities:\n",
    "    for comm_id, members in communities['communities'].items():\n",
    "        print(f\"\\n   Community {comm_id}:\")\n",
    "        for member in members[:5]:  # Show first 5 members\n",
    "            if member in kg.entities:\n",
    "                print(f\"     â€¢ {kg.entities[member].label}\")\n",
    "        if len(members) > 5:\n",
    "            print(f\"     ... and {len(members) - 5} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Temporal Knowledge Evolution\n",
    "\n",
    "Track how knowledge evolves over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track knowledge evolution\n",
    "evolution = kg.track_knowledge_evolution()\n",
    "\n",
    "print(\"â° Knowledge Evolution Analysis:\")\n",
    "for source, data in evolution.items():\n",
    "    if isinstance(data, dict) and 'entities' in data:\n",
    "        print(f\"   {source}: {data['entities']} entities\")\n",
    "        if 'types' in data:\n",
    "            print(f\"     Types: {', '.join(data['types'])}\")\n",
    "\n",
    "# For temporal graphs, you could also use:\n",
    "# temporal_kg = session.temporal_tracker\n",
    "# timeline = await temporal_kg.get_knowledge_timeline()\n",
    "print(\"\\nğŸ“ˆ Timeline analysis available with temporal features enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ Graph Visualization\n",
    "\n",
    "Visualize your knowledge graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the knowledge graph\n",
    "try:\n",
    "    kg.visualize(layout='spring', figsize=(12, 8))\n",
    "except ImportError:\n",
    "    print(\"ğŸ“Š Visualization requires matplotlib. Install with: pip install matplotlib\")\n",
    "    print(\"\\nğŸ” Graph Structure:\")\n",
    "    for entity_id, entity in kg.entities.items():\n",
    "        print(f\"   ğŸ“ {entity.label} ({entity.type})\")\n",
    "        # Find relations\n",
    "        for relation in kg.relations.values():\n",
    "            if relation.source_id == entity_id:\n",
    "                target = kg.entities.get(relation.target_id)\n",
    "                if target:\n",
    "                    print(f\"     â””â”€ {relation.type} â†’ {target.label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ Export Knowledge Graph\n",
    "\n",
    "Export your knowledge graph in various formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export in multiple formats\n",
    "export_formats = {\n",
    "    \"JSON\": \"knowledge_graph.json\",\n",
    "    \"Neo4j\": \"knowledge_graph.cypher\",\n",
    "    \"GraphML\": \"knowledge_graph.graphml\",\n",
    "    \"CSV\": \"knowledge_graph.csv\"\n",
    "}\n",
    "\n",
    "print(\"ğŸ’¾ Exporting knowledge graph:\")\n",
    "for format_name, filename in export_formats.items():\n",
    "    try:\n",
    "        kg.export(filename)\n",
    "        print(f\"   âœ… {format_name}: {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ {format_name}: {e}\")\n",
    "\n",
    "print(\"\\nğŸ“ Files created in current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ Advanced Features\n",
    "\n",
    "Explore advanced LitKG features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch processing multiple papers\n",
    "print(\"ğŸ“š Batch Processing Example:\")\n",
    "papers = [\"paper1.pdf\", \"paper2.pdf\", \"paper3.pdf\"]\n",
    "print(f\"   Would process: {', '.join(papers)}\")\n",
    "# merged_kg = session.batch_process(papers)\n",
    "\n",
    "# Custom entity and relation types\n",
    "print(\"\\nğŸ¯ Custom Types Example:\")\n",
    "session.config.custom_entities = [\"Algorithm\", \"Dataset\", \"Metric\", \"Framework\"]\n",
    "session.config.custom_relations = [\"EvaluatedOn\", \"ImplementedIn\", \"ImprovedBy\"]\n",
    "print(f\"   Custom entities: {session.config.custom_entities}\")\n",
    "print(f\"   Custom relations: {session.config.custom_relations}\")\n",
    "\n",
    "# Filter by confidence\n",
    "print(\"\\nğŸ“Š Confidence Filtering:\")\n",
    "high_conf_kg = kg.filter_by_confidence(0.9)\n",
    "print(f\"   Original: {len(kg.entities)} entities, {len(kg.relations)} relations\")\n",
    "print(f\"   High confidence (>0.9): {len(high_conf_kg.entities)} entities, {len(high_conf_kg.relations)} relations\")\n",
    "\n",
    "# Session statistics\n",
    "print(\"\\nğŸ“ˆ Session Statistics:\")\n",
    "stats = session.get_stats()\n",
    "print(f\"   Files processed: {stats.get('total_files_processed', 0)}\")\n",
    "if stats.get('active_kg_stats'):\n",
    "    kg_stats = stats['active_kg_stats']\n",
    "    print(f\"   Active KG: {kg_stats['entities']} entities, {kg_stats['relations']} relations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”Ÿ Local LLM Example\n",
    "\n",
    "Use local models with Ollama for privacy-conscious processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with local Ollama model\n",
    "print(\"ğŸ  Local LLM Example:\")\n",
    "try:\n",
    "    local_session = litkg.create_session(\n",
    "        llm=\"ollama/llama3.1\",      # Local Llama model\n",
    "        confidence_threshold=0.7,\n",
    "        local_processing=True       # All processing stays local\n",
    "    )\n",
    "    print(\"   âœ… Local session created with Llama 3.1\")\n",
    "    print(\"   ğŸ”’ All data processing stays on your machine\")\n",
    "except Exception as e:\n",
    "    print(f\"   âš ï¸ Local model not available: {e}\")\n",
    "    print(\"   ğŸ’¡ Install Ollama and run: ollama pull llama3.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‰ Conclusion\n",
    "\n",
    "You've successfully demonstrated the key features of LitKG SDK:\n",
    "\n",
    "âœ… **Simple API** - Convert PDFs to knowledge graphs in 4 lines  \n",
    "âœ… **Multi-LLM Support** - OpenAI, Anthropic, Google, local models  \n",
    "âœ… **Human-in-the-Loop** - Interactive validation for quality  \n",
    "âœ… **Advanced Analytics** - Communities, temporal tracking  \n",
    "âœ… **Multiple Exports** - JSON, Neo4j, GraphML, CSV, HTML  \n",
    "âœ… **Jupyter Integration** - Rich interactive widgets  \n",
    "\n",
    "### Next Steps:\n",
    "1. ğŸ“„ Upload your own research PDFs\n",
    "2. ğŸ¨ Customize entity and relation types for your domain\n",
    "3. ğŸ”— Connect to Neo4j for graph database storage\n",
    "4. ğŸ“Š Build dashboards with exported data\n",
    "5. ğŸ¤ Share knowledge graphs with your research team\n",
    "\n",
    "### Resources:\n",
    "- ğŸ“– [Documentation](https://lit-kg-sdk.readthedocs.io)\n",
    "- ğŸ› [Issues](https://github.com/litkg/lit-kg-sdk/issues)\n",
    "- ğŸ’¬ [Discussions](https://github.com/litkg/lit-kg-sdk/discussions)\n",
    "\n",
    "**Happy knowledge graphing! ğŸ§ ğŸ“Š**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}